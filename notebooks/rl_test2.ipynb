{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Clone repository\n",
        "import os, sys\n",
        "os.chdir(\"/content\")\n",
        "if not os.path.isdir(\"RL_DEMO\"):\n",
        "  !git clone https://github.com/Kyu3224/RL_DEMO.git\n",
        "else:\n",
        "  print(\"Cloned Directory already exists\")\n",
        "\n",
        "os.chdir(\"/content/RL_DEMO\")\n",
        "print(\"Current Directory: \", os.getcwd())\n",
        "\n",
        "sys.path.insert(0, \"/content/RL_DEMO\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gQ6Xa6gANm7",
        "outputId": "c3f3cce4-7207-489d-9b59-80417033047b"
      },
      "id": "2gQ6Xa6gANm7",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloned Directory already exists\n",
            "Current Directory:  /content/RL_DEMO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install \\\n",
        "  torch==2.2.1 \\\n",
        "  numpy \\\n",
        "  tensorboard \\\n",
        "  gymnasium==0.29.1 \\\n",
        "  protobuf==4.25.3 \\\n",
        "  stable-baselines3==2.3.0 \\\n",
        "  mujoco==3.1.5 \\\n",
        "  imageio\n",
        "\n",
        "import importlib\n",
        "from src import env\n",
        "importlib.reload(env)\n",
        "env.print_hi()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqXRzf1SCMIh",
        "outputId": "2a49f121-ea69-411c-a5b3-1ff8e0df5e33"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==2.2.1 in /usr/local/lib/python3.12/dist-packages (2.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: gymnasium==0.29.1 in /usr/local/lib/python3.12/dist-packages (0.29.1)\n",
            "Requirement already satisfied: protobuf==4.25.3 in /usr/local/lib/python3.12/dist-packages (4.25.3)\n",
            "Requirement already satisfied: stable-baselines3==2.3.0 in /usr/local/lib/python3.12/dist-packages (2.3.0)\n",
            "Requirement already satisfied: mujoco==3.1.5 in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.12/dist-packages (2.37.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.2.1) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.1) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.2.1) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.2.1) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.2.1) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.1) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.1) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.1) (12.1.105)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium==0.29.1) (3.1.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium==0.29.1) (0.0.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from stable-baselines3==2.3.0) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from stable-baselines3==2.3.0) (3.10.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mujoco==3.1.5) (1.4.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.12/dist-packages (from mujoco==3.1.5) (1.13.0)\n",
            "Requirement already satisfied: glfw in /usr/local/lib/python3.12/dist-packages (from mujoco==3.1.5) (2.10.0)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.12/dist-packages (from mujoco==3.1.5) (3.1.10)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1) (12.9.86)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboard) (25.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.1.4)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.12/dist-packages (from imageio) (11.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.3)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from etils[epath]->mujoco==3.1.5) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.12/dist-packages (from etils[epath]->mujoco==3.1.5) (3.23.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3==2.3.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3==2.3.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3==2.3.0) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3==2.3.0) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3==2.3.0) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3==2.3.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3==2.3.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3==2.3.0) (2025.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.2.1) (1.3.0)\n",
            "hi\n"
          ]
        }
      ],
      "id": "SqXRzf1SCMIh"
    },
    {
      "cell_type": "code",
      "source": [
        "from gymnasium import spaces\n",
        "from gymnasium.envs.mujoco import MujocoEnv\n",
        "\n",
        "import mujoco\n",
        "\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "DEFAULT_CAMERA_CONFIG = {\n",
        "    \"azimuth\": 90.0,\n",
        "    \"distance\": 3.0,\n",
        "    \"elevation\": -25.0,\n",
        "    \"lookat\": np.array([0., 0., 0.]),\n",
        "    \"fixedcamid\": 0,\n",
        "    \"trackbodyid\": -1,\n",
        "    \"type\": 2,\n",
        "}\n",
        "\n",
        "\n",
        "class Go1MujocoEnv(MujocoEnv):\n",
        "    \"\"\"Custom Environment that follows gym interface.\"\"\"\n",
        "\n",
        "    metadata = {\n",
        "        \"render_modes\": [\n",
        "            \"human\",\n",
        "            \"rgb_array\",\n",
        "            \"depth_array\",\n",
        "        ],\n",
        "    }\n",
        "\n",
        "    def __init__(self, ctrl_type=\"torque\", **kwargs):\n",
        "        model_path = Path(f\"./unitree_go1/scene_{ctrl_type}.xml\")\n",
        "        MujocoEnv.__init__(\n",
        "            self,\n",
        "            model_path=model_path.absolute().as_posix(),\n",
        "            frame_skip=10,  # Perform an action every 10 frames (dt(=0.002) * 10 = 0.02 seconds -> 50hz action rate)\n",
        "            observation_space=None,  # Manually set afterwards\n",
        "            default_camera_config=DEFAULT_CAMERA_CONFIG,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "        # Update metadata to include the render FPS\n",
        "        self.metadata = {\n",
        "            \"render_modes\": [\n",
        "                \"human\",\n",
        "                \"rgb_array\",\n",
        "                \"depth_array\",\n",
        "            ],\n",
        "            \"render_fps\": 60,\n",
        "        }\n",
        "        self._last_render_time = -1.0\n",
        "        self._max_episode_time_sec = 15.0\n",
        "        self._step = 0\n",
        "\n",
        "        # Weights for the reward and cost functions\n",
        "        self.reward_weights = {\n",
        "            \"linear_vel_tracking\": 2.0,  # Was 1.0\n",
        "            \"angular_vel_tracking\": 1.0,\n",
        "            \"healthy\": 0.0,  # was 0.05\n",
        "            \"feet_airtime\": 1.0,\n",
        "        }\n",
        "        self.cost_weights = {\n",
        "            \"torque\": 0.0002,\n",
        "            \"vertical_vel\": 2.0,  # Was 1.0\n",
        "            \"xy_angular_vel\": 0.05,  # Was 0.05\n",
        "            \"action_rate\": 0.01,\n",
        "            \"joint_limit\": 10.0,\n",
        "            \"joint_velocity\": 0.01,\n",
        "            \"joint_acceleration\": 2.5e-7,\n",
        "            \"orientation\": 1.0,\n",
        "            \"collision\": 1.0,\n",
        "            \"default_joint_position\": 0.1\n",
        "        }\n",
        "\n",
        "        self._curriculum_base = 0.3\n",
        "        self._gravity_vector = np.array(self.model.opt.gravity)\n",
        "        self._default_joint_position = np.array(self.model.key_ctrl[0])\n",
        "\n",
        "        # vx (m/s), vy (m/s), wz (rad/s)\n",
        "        self._desired_velocity_min = np.array([0.5, -0.0, -0.0])\n",
        "        self._desired_velocity_max = np.array([0.5, 0.0, 0.0])\n",
        "        self._desired_velocity = self._sample_desired_vel()  # [0.5, 0.0, 0.0]\n",
        "        self._obs_scale = {\n",
        "            \"linear_velocity\": 2.0,\n",
        "            \"angular_velocity\": 0.25,\n",
        "            \"dofs_position\": 1.0,\n",
        "            \"dofs_velocity\": 0.05,\n",
        "        }\n",
        "        self._tracking_velocity_sigma = 0.25\n",
        "\n",
        "        # Metrics used to determine if the episode should be terminated\n",
        "        self._healthy_z_range = (0.22, 0.65)\n",
        "        self._healthy_pitch_range = (-np.deg2rad(10), np.deg2rad(10))\n",
        "        self._healthy_roll_range = (-np.deg2rad(10), np.deg2rad(10))\n",
        "\n",
        "        self._feet_air_time = np.zeros(4)\n",
        "        self._last_contacts = np.zeros(4)\n",
        "        self._cfrc_ext_feet_indices = [4, 7, 10, 13]  # 4:FR, 7:FL, 10:RR, 13:RL\n",
        "        self._cfrc_ext_contact_indices = [2, 3, 5, 6, 8, 9, 11, 12]\n",
        "\n",
        "        # Non-penalized degrees of freedom range of the control joints\n",
        "        dof_position_limit_multiplier = 0.9  # The % of the range that is not penalized\n",
        "        ctrl_range_offset = (\n",
        "            0.5\n",
        "            * (1 - dof_position_limit_multiplier)\n",
        "            * (\n",
        "                self.model.actuator_ctrlrange[:, 1]\n",
        "                - self.model.actuator_ctrlrange[:, 0]\n",
        "            )\n",
        "        )\n",
        "        # First value is the root joint, so we ignore it\n",
        "        self._soft_joint_range = np.copy(self.model.actuator_ctrlrange)\n",
        "        self._soft_joint_range[:, 0] += ctrl_range_offset\n",
        "        self._soft_joint_range[:, 1] -= ctrl_range_offset\n",
        "\n",
        "        self._reset_noise_scale = 0.1\n",
        "\n",
        "        # Action: 12 torque values\n",
        "        self._last_action = np.zeros(12)\n",
        "\n",
        "        self._clip_obs_threshold = 100.0\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=-np.inf, high=np.inf, shape=self._get_obs().shape, dtype=np.float64\n",
        "        )\n",
        "\n",
        "        # Feet site names to index mapping\n",
        "        # https://mujoco.readthedocs.io/en/stable/XMLreference.html#body-site\n",
        "        # https://mujoco.readthedocs.io/en/stable/APIreference/APItypes.html#mjtobj\n",
        "        feet_site = [\n",
        "            \"FR\",\n",
        "            \"FL\",\n",
        "            \"RR\",\n",
        "            \"RL\",\n",
        "        ]\n",
        "        self._feet_site_name_to_id = {\n",
        "            f: mujoco.mj_name2id(self.model, mujoco.mjtObj.mjOBJ_SITE.value, f)\n",
        "            for f in feet_site\n",
        "        }\n",
        "\n",
        "        self._main_body_id = mujoco.mj_name2id(\n",
        "            self.model, mujoco.mjtObj.mjOBJ_BODY.value, \"trunk\"\n",
        "        )\n",
        "\n",
        "    def step(self, action):\n",
        "        self._step += 1\n",
        "        self.do_simulation(action, self.frame_skip)\n",
        "\n",
        "        observation = self._get_obs()\n",
        "        reward, reward_info = self._calc_reward(action)\n",
        "        # TODO: Consider terminating if knees touch the ground\n",
        "        terminated = not self.is_healthy\n",
        "        truncated = self._step >= (self._max_episode_time_sec / self.dt)\n",
        "        info = {\n",
        "            \"x_position\": self.data.qpos[0],\n",
        "            \"y_position\": self.data.qpos[1],\n",
        "            \"distance_from_origin\": np.linalg.norm(self.data.qpos[0:2], ord=2),\n",
        "            **reward_info,\n",
        "        }\n",
        "\n",
        "        if self.render_mode == \"human\" and (self.data.time - self._last_render_time) > (\n",
        "            1.0 / self.metadata[\"render_fps\"]\n",
        "        ):\n",
        "            self.render()\n",
        "            self._last_render_time = self.data.time\n",
        "\n",
        "        self._last_action = action\n",
        "\n",
        "        return observation, reward, terminated, truncated, info\n",
        "\n",
        "    @property\n",
        "    def is_healthy(self):\n",
        "        state = self.state_vector()\n",
        "        min_z, max_z = self._healthy_z_range\n",
        "        is_healthy = np.isfinite(state).all() and min_z <= state[2] <= max_z\n",
        "\n",
        "        min_roll, max_roll = self._healthy_roll_range\n",
        "        is_healthy = is_healthy and min_roll <= state[4] <= max_roll\n",
        "\n",
        "        min_pitch, max_pitch = self._healthy_pitch_range\n",
        "        is_healthy = is_healthy and min_pitch <= state[5] <= max_pitch\n",
        "\n",
        "        return is_healthy\n",
        "\n",
        "    @property\n",
        "    def projected_gravity(self):\n",
        "        w, x, y, z = self.data.qpos[3:7]\n",
        "        euler_orientation = np.array(self.euler_from_quaternion(w, x, y, z))\n",
        "        projected_gravity_not_normalized = (\n",
        "            np.dot(self._gravity_vector, euler_orientation) * euler_orientation\n",
        "        )\n",
        "        if np.linalg.norm(projected_gravity_not_normalized) == 0:\n",
        "            return projected_gravity_not_normalized\n",
        "        else:\n",
        "            return projected_gravity_not_normalized / np.linalg.norm(\n",
        "                projected_gravity_not_normalized\n",
        "            )\n",
        "\n",
        "    @property\n",
        "    def feet_contact_forces(self):\n",
        "        feet_contact_forces = self.data.cfrc_ext[self._cfrc_ext_feet_indices]\n",
        "        return np.linalg.norm(feet_contact_forces, axis=1)\n",
        "\n",
        "    ######### Positive Reward functions #########\n",
        "    @property\n",
        "    def linear_velocity_tracking_reward(self):\n",
        "        vel_sqr_error = np.sum(\n",
        "            np.square(self._desired_velocity[:2] - self.data.qvel[:2])\n",
        "        )\n",
        "        return np.exp(-vel_sqr_error / self._tracking_velocity_sigma)\n",
        "\n",
        "    @property\n",
        "    def angular_velocity_tracking_reward(self):\n",
        "        vel_sqr_error = np.square(self._desired_velocity[2] - self.data.qvel[5])\n",
        "        return np.exp(-vel_sqr_error / self._tracking_velocity_sigma)\n",
        "\n",
        "    @property\n",
        "    def heading_tracking_reward(self):\n",
        "        # TODO: qpos[3:7] are the quaternion values\n",
        "        pass\n",
        "\n",
        "    @property\n",
        "    def feet_air_time_reward(self):\n",
        "        \"\"\"Award strides depending on their duration only when the feet makes contact with the ground\"\"\"\n",
        "        feet_contact_force_mag = self.feet_contact_forces\n",
        "        curr_contact = feet_contact_force_mag > 1.0\n",
        "        contact_filter = np.logical_or(curr_contact, self._last_contacts)\n",
        "        self._last_contacts = curr_contact\n",
        "\n",
        "        # if feet_air_time is > 0 (feet was in the air) and contact_filter detects a contact with the ground\n",
        "        # then it is the first contact of this stride\n",
        "        first_contact = (self._feet_air_time > 0.0) * contact_filter\n",
        "        self._feet_air_time += self.dt\n",
        "\n",
        "        # Award the feets that have just finished their stride (first step with contact)\n",
        "        air_time_reward = np.sum((self._feet_air_time - 1.0) * first_contact)\n",
        "        # No award if the desired velocity is very low (i.e. robot should remain stationary and feet shouldn't move)\n",
        "        air_time_reward *= np.linalg.norm(self._desired_velocity[:2]) > 0.1\n",
        "\n",
        "        # zero-out the air time for the feet that have just made contact (i.e. contact_filter==1)\n",
        "        self._feet_air_time *= ~contact_filter\n",
        "\n",
        "        return air_time_reward\n",
        "\n",
        "    @property\n",
        "    def healthy_reward(self):\n",
        "        return self.is_healthy\n",
        "\n",
        "    ######### Negative Reward functions #########\n",
        "    @property  # TODO: Not used\n",
        "    def feet_contact_forces_cost(self):\n",
        "        return np.sum(\n",
        "            (self.feet_contact_forces - self._max_contact_force).clip(min=0.0)\n",
        "        )\n",
        "\n",
        "    @property\n",
        "    def non_flat_base_cost(self):\n",
        "        # Penalize the robot for not being flat on the ground\n",
        "        return np.sum(np.square(self.projected_gravity[:2]))\n",
        "\n",
        "    @property\n",
        "    def collision_cost(self):\n",
        "        # Penalize collisions on selected bodies\n",
        "        return np.sum(\n",
        "            1.0\n",
        "            * (np.linalg.norm(self.data.cfrc_ext[self._cfrc_ext_contact_indices]) > 0.1)\n",
        "        )\n",
        "\n",
        "    @property\n",
        "    def joint_limit_cost(self):\n",
        "        # Penalize the robot for joints exceeding the soft control range\n",
        "        out_of_range = (self._soft_joint_range[:, 0] - self.data.qpos[7:]).clip(\n",
        "            min=0.0\n",
        "        ) + (self.data.qpos[7:] - self._soft_joint_range[:, 1]).clip(min=0.0)\n",
        "        return np.sum(out_of_range)\n",
        "\n",
        "    @property\n",
        "    def torque_cost(self):\n",
        "        # Last 12 values are the motor torques\n",
        "        return np.sum(np.square(self.data.qfrc_actuator[-12:]))\n",
        "\n",
        "    @property\n",
        "    def vertical_velocity_cost(self):\n",
        "        return np.square(self.data.qvel[2])\n",
        "\n",
        "    @property\n",
        "    def xy_angular_velocity_cost(self):\n",
        "        return np.sum(np.square(self.data.qvel[3:5]))\n",
        "\n",
        "    def action_rate_cost(self, action):\n",
        "        return np.sum(np.square(self._last_action - action))\n",
        "\n",
        "    @property\n",
        "    def joint_velocity_cost(self):\n",
        "        return np.sum(np.square(self.data.qvel[6:]))\n",
        "\n",
        "    @property\n",
        "    def acceleration_cost(self):\n",
        "        return np.sum(np.square(self.data.qacc[6:]))\n",
        "\n",
        "    @property\n",
        "    def default_joint_position_cost(self):\n",
        "        return np.sum(np.square(self.data.qpos[7:] - self._default_joint_position))\n",
        "\n",
        "    @property\n",
        "    def smoothness_cost(self):\n",
        "        return np.sum(np.square(self.data.qpos[7:] - self._last_action))\n",
        "\n",
        "    @property\n",
        "    def curriculum_factor(self):\n",
        "        return self._curriculum_base**0.997\n",
        "\n",
        "    def _calc_reward(self, action):\n",
        "        # TODO: Add debug mode with custom Tensorboard calls for individual reward\n",
        "        #   functions to get a better sense of the contribution of each reward function\n",
        "        # TODO: Cost for thigh or calf contact with the ground\n",
        "\n",
        "        # Positive Rewards\n",
        "        linear_vel_tracking_reward = (\n",
        "            self.linear_velocity_tracking_reward\n",
        "            * self.reward_weights[\"linear_vel_tracking\"]\n",
        "        )\n",
        "        angular_vel_tracking_reward = (\n",
        "            self.angular_velocity_tracking_reward\n",
        "            * self.reward_weights[\"angular_vel_tracking\"]\n",
        "        )\n",
        "        healthy_reward = self.healthy_reward * self.reward_weights[\"healthy\"]\n",
        "        feet_air_time_reward = (\n",
        "            self.feet_air_time_reward * self.reward_weights[\"feet_airtime\"]\n",
        "        )\n",
        "        rewards = (\n",
        "            linear_vel_tracking_reward\n",
        "            + angular_vel_tracking_reward\n",
        "            + healthy_reward\n",
        "            + feet_air_time_reward\n",
        "        )\n",
        "\n",
        "        # Negative Costs\n",
        "        ctrl_cost = self.torque_cost * self.cost_weights[\"torque\"]\n",
        "        action_rate_cost = (\n",
        "            self.action_rate_cost(action) * self.cost_weights[\"action_rate\"]\n",
        "        )\n",
        "        vertical_vel_cost = (\n",
        "            self.vertical_velocity_cost * self.cost_weights[\"vertical_vel\"]\n",
        "        )\n",
        "        xy_angular_vel_cost = (\n",
        "            self.xy_angular_velocity_cost * self.cost_weights[\"xy_angular_vel\"]\n",
        "        )\n",
        "        joint_limit_cost = self.joint_limit_cost * self.cost_weights[\"joint_limit\"]\n",
        "        joint_velocity_cost = (\n",
        "            self.joint_velocity_cost * self.cost_weights[\"joint_velocity\"]\n",
        "        )\n",
        "        joint_acceleration_cost = (\n",
        "            self.acceleration_cost * self.cost_weights[\"joint_acceleration\"]\n",
        "        )\n",
        "        orientation_cost = self.non_flat_base_cost * self.cost_weights[\"orientation\"]\n",
        "        collision_cost = self.collision_cost * self.cost_weights[\"collision\"]\n",
        "        default_joint_position_cost = (\n",
        "            self.default_joint_position_cost\n",
        "            * self.cost_weights[\"default_joint_position\"]\n",
        "        )\n",
        "        costs = (\n",
        "            ctrl_cost\n",
        "            + action_rate_cost\n",
        "            + vertical_vel_cost\n",
        "            + xy_angular_vel_cost\n",
        "            + joint_limit_cost\n",
        "            + joint_acceleration_cost\n",
        "            + orientation_cost\n",
        "            + default_joint_position_cost\n",
        "        )\n",
        "\n",
        "        reward = max(0.0, rewards - costs)\n",
        "        # reward = rewards - self.curriculum_factor * costs\n",
        "        reward_info = {\n",
        "            \"linear_vel_tracking_reward\": linear_vel_tracking_reward,\n",
        "            \"reward_ctrl\": -ctrl_cost,\n",
        "            \"reward_survive\": healthy_reward,\n",
        "        }\n",
        "\n",
        "        return reward, reward_info\n",
        "\n",
        "    def _get_obs(self):\n",
        "        # The first three indices are the global x,y,z position of the trunk of the robot\n",
        "        # The second four are the quaternion representing the orientation of the robot\n",
        "        # The above seven values are ignored since they are privileged information\n",
        "        # The remaining 12 values are the joint positions\n",
        "        # The joint positions are relative to the starting position\n",
        "        dofs_position = self.data.qpos[7:].flatten() - self.model.key_qpos[0, 7:]\n",
        "\n",
        "        # The first three values are the global linear velocity of the robot\n",
        "        # The second three are the angular velocity of the robot\n",
        "        # The remaining 12 values are the joint velocities\n",
        "        velocity = self.data.qvel.flatten()\n",
        "        base_linear_velocity = velocity[:3]\n",
        "        base_angular_velocity = velocity[3:6]\n",
        "        dofs_velocity = velocity[6:]\n",
        "\n",
        "        desired_vel = self._desired_velocity\n",
        "        last_action = self._last_action\n",
        "        projected_gravity = self.projected_gravity\n",
        "\n",
        "        curr_obs = np.concatenate(\n",
        "            (\n",
        "                base_linear_velocity * self._obs_scale[\"linear_velocity\"],\n",
        "                base_angular_velocity * self._obs_scale[\"angular_velocity\"],\n",
        "                projected_gravity,\n",
        "                desired_vel * self._obs_scale[\"linear_velocity\"],\n",
        "                dofs_position * self._obs_scale[\"dofs_position\"],\n",
        "                dofs_velocity * self._obs_scale[\"dofs_velocity\"],\n",
        "                last_action,\n",
        "            )\n",
        "        ).clip(-self._clip_obs_threshold, self._clip_obs_threshold)\n",
        "\n",
        "        return curr_obs\n",
        "\n",
        "    def reset_model(self):\n",
        "        # Reset the position and control values with noise\n",
        "        self.data.qpos[:] = self.model.key_qpos[0] + self.np_random.uniform(\n",
        "            low=-self._reset_noise_scale,\n",
        "            high=self._reset_noise_scale,\n",
        "            size=self.model.nq,\n",
        "        )\n",
        "        self.data.ctrl[:] = self.model.key_ctrl[\n",
        "            0\n",
        "        ] + self._reset_noise_scale * self.np_random.standard_normal(\n",
        "            *self.data.ctrl.shape\n",
        "        )\n",
        "\n",
        "        # Reset the variables and sample a new desired velocity\n",
        "        self._desired_velocity = self._sample_desired_vel()\n",
        "        self._step = 0\n",
        "        self._last_action = np.zeros(12)\n",
        "        self._feet_air_time = np.zeros(4)\n",
        "        self._last_contacts = np.zeros(4)\n",
        "        self._last_render_time = -1.0\n",
        "\n",
        "        observation = self._get_obs()\n",
        "\n",
        "        return observation\n",
        "\n",
        "    def _get_reset_info(self):\n",
        "        return {\n",
        "            \"x_position\": self.data.qpos[0],\n",
        "            \"y_position\": self.data.qpos[1],\n",
        "            \"distance_from_origin\": np.linalg.norm(self.data.qpos[0:2], ord=2),\n",
        "        }\n",
        "\n",
        "    def _sample_desired_vel(self):\n",
        "        desired_vel = np.random.default_rng().uniform(\n",
        "            low=self._desired_velocity_min, high=self._desired_velocity_max\n",
        "        )\n",
        "        return desired_vel\n",
        "\n",
        "    @staticmethod\n",
        "    def euler_from_quaternion(w, x, y, z):\n",
        "        \"\"\"\n",
        "        Convert a quaternion into euler angles (roll, pitch, yaw)\n",
        "        roll is rotation around x in radians (counterclockwise)\n",
        "        pitch is rotation around y in radians (counterclockwise)\n",
        "        yaw is rotation around z in radians (counterclockwise)\n",
        "        \"\"\"\n",
        "        t0 = +2.0 * (w * x + y * z)\n",
        "        t1 = +1.0 - 2.0 * (x * x + y * y)\n",
        "        roll_x = np.arctan2(t0, t1)\n",
        "\n",
        "        t2 = +2.0 * (w * y - z * x)\n",
        "        t2 = +1.0 if t2 > +1.0 else t2\n",
        "        t2 = -1.0 if t2 < -1.0 else t2\n",
        "        pitch_y = np.arcsin(t2)\n",
        "\n",
        "        t3 = +2.0 * (w * z + x * y)\n",
        "        t4 = +1.0 - 2.0 * (y * y + z * z)\n",
        "        yaw_z = np.arctan2(t3, t4)\n",
        "\n",
        "        return roll_x, pitch_y, yaw_z  # in radians\n"
      ],
      "metadata": {
        "id": "DOx9Hd8DDCUI"
      },
      "id": "DOx9Hd8DDCUI",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "import gymnasium as gym\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from tqdm import tqdm\n",
        "\n",
        "MODEL_DIR = \"models\"\n",
        "LOG_DIR = \"logs\"\n",
        "\n",
        "\n",
        "def train(args):\n",
        "    vec_env = make_vec_env(\n",
        "        Go1MujocoEnv,\n",
        "        env_kwargs={\"ctrl_type\": \"position\"},\n",
        "        n_envs=args.num_envs,\n",
        "        seed=args.seed,\n",
        "        vec_env_cls=SubprocVecEnv,\n",
        "    )\n",
        "\n",
        "    train_time = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    if args.run_name is None:\n",
        "        run_name = f\"{train_time}\"\n",
        "    else:\n",
        "        run_name = f\"{train_time}-{args.run_name}\"\n",
        "\n",
        "    model_path = f\"{MODEL_DIR}/{run_name}\"\n",
        "    print(\n",
        "        f\"Training on {args.num_envs} parallel training environments and saving models to '{model_path}'\"\n",
        "    )\n",
        "\n",
        "    # Evaluate the model every eval_frequency for 5 episodes and save\n",
        "    # it if it's improved over the previous best model.\n",
        "    eval_callback = EvalCallback(\n",
        "        vec_env,\n",
        "        best_model_save_path=model_path,\n",
        "        log_path=LOG_DIR,\n",
        "        eval_freq=args.eval_frequency,\n",
        "        n_eval_episodes=5,\n",
        "        deterministic=True,\n",
        "        render=False,\n",
        "    )\n",
        "\n",
        "    if args.model_path is not None:\n",
        "        model = PPO.load(\n",
        "            path=args.model_path, env=vec_env, verbose=1, tensorboard_log=LOG_DIR\n",
        "        )\n",
        "    else:\n",
        "        # Default PPO model hyper-parameters give good results\n",
        "        # TODO: Use dynamic learning rate\n",
        "        model = PPO(\"MlpPolicy\", vec_env, verbose=1, tensorboard_log=LOG_DIR)\n",
        "\n",
        "    model.learn(\n",
        "        total_timesteps=args.total_timesteps,\n",
        "        reset_num_timesteps=False,\n",
        "        progress_bar=True,\n",
        "        tb_log_name=run_name,\n",
        "        callback=eval_callback,\n",
        "    )\n",
        "    # Save final model\n",
        "    model.save(f\"{model_path}/final_model\")\n",
        "\n",
        "\n",
        "def test(args):\n",
        "    model_path = Path(args.model_path)\n",
        "\n",
        "    if not args.record_test_episodes:\n",
        "        # Render the episodes live\n",
        "        env = Go1MujocoEnv(\n",
        "            ctrl_type=args.ctrl_type,\n",
        "            render_mode=\"human\",\n",
        "        )\n",
        "        inter_frame_sleep = 0.016\n",
        "    else:\n",
        "        # Record the episodes\n",
        "        env = Go1MujocoEnv(\n",
        "            ctrl_type=args.ctrl_type,\n",
        "            render_mode=\"rgb_array\",\n",
        "            camera_name=\"tracking\",\n",
        "            width=1920,\n",
        "            height=1080,\n",
        "        )\n",
        "        env = gym.wrappers.RecordVideo(\n",
        "            env, video_folder=\"recordings/\", name_prefix=model_path.parent.name\n",
        "        )\n",
        "        inter_frame_sleep = 0.0\n",
        "\n",
        "    model = PPO.load(path=model_path, env=env, verbose=1)\n",
        "\n",
        "    num_episodes = args.num_test_episodes\n",
        "    total_reward = 0\n",
        "    total_length = 0\n",
        "    for _ in tqdm(range(num_episodes)):\n",
        "        obs, _ = env.reset()\n",
        "        env.render()\n",
        "\n",
        "        ep_len = 0\n",
        "        ep_reward = 0\n",
        "        while True:\n",
        "            action, _ = model.predict(obs, deterministic=True)\n",
        "            obs, reward, terminated, truncated, info = env.step(action)\n",
        "            ep_reward += reward\n",
        "            ep_len += 1\n",
        "\n",
        "            # Slow down the rendering\n",
        "            time.sleep(inter_frame_sleep)\n",
        "\n",
        "            if terminated or truncated:\n",
        "                print(f\"{ep_len=}  {ep_reward=}\")\n",
        "                break\n",
        "\n",
        "        total_length += ep_len\n",
        "        total_reward += ep_reward\n",
        "\n",
        "    print(\n",
        "        f\"Avg episode reward: {total_reward / num_episodes}, avg episode length: {total_length / num_episodes}\"\n",
        "    )\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\n",
        "        \"--run_name\",\n",
        "        type=str,\n",
        "        default=None,\n",
        "        help=\"Custom name of the run. Note that all runs are saved in the 'models' directory and have the training time prefixed.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--num_envs\",\n",
        "        type=int,\n",
        "        default=12,\n",
        "        help=\"Number of parallel environments while training\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--num_test_episodes\",\n",
        "        type=int,\n",
        "        default=5,\n",
        "        help=\"Number of episodes to test the model\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--record_test_episodes\",\n",
        "        action=\"store_true\",\n",
        "        help=\"Whether to record the test episodes or not. If false, the episodes are rendered in the window.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--total_timesteps\",\n",
        "        type=int,\n",
        "        default=5_000_000,\n",
        "        help=\"Number of timesteps to train the model for\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--eval_frequency\",\n",
        "        type=int,\n",
        "        default=10_000,\n",
        "        help=\"The frequency of evaluating the models while training\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--model_path\",\n",
        "        type=str,\n",
        "        default=None,\n",
        "        help=\"Path to the model (.zip). If passed for training, the model is used as the starting point for training. If passed for testing, the model is used for inference.\",\n",
        "    )\n",
        "    parser.add_argument(\"--seed\", type=int, default=0)\n",
        "    args, unknown = parser.parse_known_args()\n",
        "\n",
        "    # if args.run == \"train\":\n",
        "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "    os.makedirs(LOG_DIR, exist_ok=True)\n",
        "    train(args)\n",
        "    # elif args.run == \"test\":\n",
        "    #     if args.model_path is None:\n",
        "    #         raise ValueError(\"--model_path is required for testing\")\n",
        "    #     test(args)\n"
      ],
      "metadata": {
        "id": "Bnov5JM1DJfT",
        "outputId": "39df6522-3f7e-4d42-a84a-7692cecc0d1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 981
        }
      },
      "id": "Bnov5JM1DJfT",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ConnectionResetError",
          "evalue": "[Errno 104] Connection reset by peer",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3295071358.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOG_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m     \u001b[0;31m# elif args.run == \"test\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;31m#     if args.model_path is None:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3295071358.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     vec_env = make_vec_env(\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mGo1MujocoEnv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0menv_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"ctrl_type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"position\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/stable_baselines3/common/env_util.py\u001b[0m in \u001b[0;36mmake_vec_env\u001b[0;34m(env_id, n_envs, seed, start_index, monitor_dir, wrapper_class, env_kwargs, vec_env_cls, vec_env_kwargs, monitor_kwargs, wrapper_kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mvec_env_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDummyVecEnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mvec_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec_env_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmake_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstart_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mvec_env_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0;31m# Prepare the seeds for the first reset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mvec_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/stable_baselines3/common/vec_env/subproc_vec_env.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env_fns, start_method)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremotes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get_spaces\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mobservation_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremotes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectionResetError\u001b[0m: [Errno 104] Connection reset by peer"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JNP_D7VTGY5c"
      },
      "id": "JNP_D7VTGY5c",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}